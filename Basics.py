# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ogJJmI7Py5G_rO6FXYeeyT_VO5AQc8QI
"""

import tensorflow as tf
print("TensorFlow version:", tf.__version__)

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize data

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),  # Convert 2D to 1D
  tf.keras.layers.Dense(128, activation='relu'),  # Hidden layer with ReLU activation
  tf.keras.layers.Dropout(0.2),  # Dropout layer to prevent overfitting
  tf.keras.layers.Dense(10)  # Output layer with 10 classes
])

loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

model.compile(optimizer='adam',
              loss=loss_fn,
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)

model.evaluate(x_test, y_test, verbose=2)

probability_model = tf.keras.Sequential([
  model,
  tf.keras.layers.Softmax()
])

probability_model(x_test[:5])

model.save("mnist_model.h5")

model.save('my_model.keras')

