{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-nightly\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy5nv0YLoL-U",
        "outputId": "c669f5e1-258a-4bdf-e92f-bfcee1753f47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.10/dist-packages (2.20.0.dev20250211)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.68.1)\n",
            "Requirement already satisfied: tb-nightly~=2.19.0.a in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.19.0a20250217)\n",
            "Requirement already satisfied: keras-nightly>=3.6.0.dev in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.8.0.dev2025021803)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.12.1)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tf-nightly)\n",
            "  Using cached ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.19.0.a->tf-nightly) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nightly>=3.6.0.dev->tf-nightly) (0.1.2)\n",
            "Using cached ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Installing collected packages: ml-dtypes\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires ml-dtypes<0.5.0,>=0.3.1, but you have ml-dtypes 0.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "za59wJDyoMPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall ml-dtypes -y\n",
        "!pip install ml-dtypes==0.4.1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTLP9tDdoN5s",
        "outputId": "5271b0c2-76e0-4d20-c3bb-24f2a1c0e2ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: ml_dtypes 0.5.1\n",
            "Uninstalling ml_dtypes-0.5.1:\n",
            "  Successfully uninstalled ml_dtypes-0.5.1\n",
            "Collecting ml-dtypes==0.4.1\n",
            "  Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.10/dist-packages (from ml-dtypes==0.4.1) (1.26.4)\n",
            "Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Installing collected packages: ml-dtypes\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-nightly 2.20.0.dev20250211 requires ml-dtypes<1.0.0,>=0.5.1, but you have ml-dtypes 0.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NkVk2M30oQRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n"
      ],
      "metadata": {
        "id": "iiePWDBVoQ0p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create mnist_setup.py file with dataset and model functions\n",
        "%%writefile mnist_setup.py\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def mnist_dataset(batch_size):\n",
        "    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "    # Normalize and preprocess the dataset\n",
        "    x_train = x_train / np.float32(255)\n",
        "    y_train = y_train.astype(np.int64)\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)) \\\n",
        "        .shuffle(60000).repeat().batch(batch_size)\n",
        "    return train_dataset\n",
        "\n",
        "def build_and_compile_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3EeFRCFoSM5",
        "outputId": "03348073-870d-4c8d-cc2e-3de4a1ff2f1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mnist_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mnist_setup\n",
        "\n",
        "# Set the batch size for a single worker\n",
        "batch_size = 64\n",
        "single_worker_dataset = mnist_setup.mnist_dataset(batch_size)\n",
        "single_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "\n",
        "# Train the model on a single worker\n",
        "single_worker_model.fit(single_worker_dataset, epochs=3, steps_per_epoch=70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaZEzJXRoU7Y",
        "outputId": "3753e0d6-98b1-463c-959d-bb127add2bb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "AttributeError: module 'ml_dtypes' has no attribute 'float4_e2m1fn'\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.1383 - loss: 2.2946\n",
            "Epoch 2/3\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.3699 - loss: 2.2323\n",
            "Epoch 3/3\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.5648 - loss: 2.1632\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a75a88a2f50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N3YgiRUaoabM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Worker Mirrored Strategy setup\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "# Configure TF_CONFIG for Multi-Worker Training\n",
        "tf_config = {\n",
        "    'cluster': {\n",
        "        'worker': ['localhost:12345', 'localhost:23456']  # Define two workers on the same machine\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}  # The first worker (index 0)\n",
        "}\n",
        "\n",
        "# Set TF_CONFIG environment variable\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-od-eYaodS2",
        "outputId": "53597910-ffa6-4f47-d889-4ae2067c1702"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using MultiWorkerMirroredStrategy\n",
        "per_worker_batch_size = 64\n",
        "num_workers = len(tf_config['cluster']['worker'])\n",
        "\n",
        "global_batch_size = per_worker_batch_size * num_workers\n",
        "multi_worker_dataset = mnist_setup.mnist_dataset(global_batch_size)\n",
        "\n",
        "with strategy.scope():\n",
        "    multi_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "\n",
        "# Train the model across multiple workers\n",
        "multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-_ThM69ogq7",
        "outputId": "d08d2350-7261-4771-ccdd-fe6bec86870e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.1110 - loss: 2.2802\n",
            "Epoch 2/3\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - accuracy: 0.3254 - loss: 2.2051\n",
            "Epoch 3/3\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5118 - loss: 2.1181\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a75a4c92d70>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "import os\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import mnist_setup\n",
        "\n",
        "# Set batch size for each worker\n",
        "per_worker_batch_size = 64\n",
        "tf_config = json.loads(os.environ['TF_CONFIG'])\n",
        "num_workers = len(tf_config['cluster']['worker'])\n",
        "\n",
        "# Initialize MultiWorkerMirroredStrategy\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "global_batch_size = per_worker_batch_size * num_workers\n",
        "multi_worker_dataset = mnist_setup.mnist_dataset(global_batch_size)\n",
        "\n",
        "with strategy.scope():\n",
        "    multi_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "\n",
        "multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF7W60KhojHr",
        "outputId": "fbad7d7e-d1af-4c46-e1f9-b302e57512ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)\n",
        "!python main.py &> job_0.log &\n"
      ],
      "metadata": {
        "id": "SzkAB0-aoufV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the worker index to 1 for the second worker\n",
        "tf_config['task']['index'] = 1\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)\n",
        "!python main.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rawmBWjdoybM",
        "outputId": "903003c1-a374-4a32-e6a7-e4aa542c06dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-18 10:38:34.952448: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1739875114.962322    2510 grpc_server_lib.cc:463] Started server with target: grpc://localhost:23456\n",
            "I0000 00:00:1739875114.965457    2510 coordination_service_agent.cc:369] Coordination agent has successfully connected.\n",
            "AttributeError: module 'ml_dtypes' has no attribute 'float4_e2m1fn'\n",
            "2025-02-18 10:38:36.329372: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n",
            "2025-02-18 10:38:36.930076: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n",
            "2025-02-18 10:38:37.174309: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n",
            "2025-02-18 10:38:37.482258: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/main.py\", line 20, in <module>\n",
            "    multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 108, in convert_to_eager_tensor\n",
            "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
            "ValueError: Attempt to convert a value (PerReplica:{\n",
            "  0: <tf.Tensor: shape=(64, 28, 28), dtype=float32, numpy=\n",
            "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>\n",
            "}) with an unsupported type (<class 'tensorflow.python.distribute.values.PerReplica'>) to a Tensor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the worker index to 1 for the second worker\n",
        "tf_config['task']['index'] = 1\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)\n",
        "!python main.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwpigCkqo0MQ",
        "outputId": "6ffa789e-7009-4d86-dbd5-1244979b8e22"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-18 10:38:59.747699: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1739875139.756805    2763 grpc_server_lib.cc:463] Started server with target: grpc://localhost:23456\n",
            "2025-02-18 11:39:04.759278: E tensorflow/core/common_runtime/base_collective_executor.cc:248] BaseCollectiveExecutor::StartAbort DEADLINE_EXCEEDED: Deadline Exceeded\n",
            "\n",
            "RPC: /tensorflow.CoordinationService/RegisterTask\n",
            "E0000 00:00:1739878744.759543    2763 context_distributed_manager.cc:1107] Deadline Exceeded\n",
            "Additional GRPC error information from remote target /job:worker/replica:0/task:0 while calling /tensorflow.CoordinationService/RegisterTask:\n",
            ":{\"created\":\"@1739878744.756606172\",\"description\":\"Deadline Exceeded\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/filters/deadline/deadline_filter.cc\",\"file_line\":69,\"grpc_status\":4}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/main.py\", line 12, in <module>\n",
            "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 187, in __init__\n",
            "    CollectiveAllReduceExtended(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 381, in __init__\n",
            "    self._initialize_strategy(self._cluster_resolver, devices=devices)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 401, in _initialize_strategy\n",
            "    self._initialize_multi_worker(cluster_resolver)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 602, in _initialize_multi_worker\n",
            "    context.context().ensure_initialized()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\", line 745, in ensure_initialized\n",
            "    pywrap_tfe.TFE_EnableCollectiveOps(context_handle, server_def_str)\n",
            "tensorflow.python.framework.errors_impl.DeadlineExceededError: Deadline Exceeded\n",
            "Additional GRPC error information from remote target /job:worker/replica:0/task:0 while calling /tensorflow.CoordinationService/RegisterTask:\n",
            ":{\"created\":\"@1739878744.756606172\",\"description\":\"Deadline Exceeded\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/filters/deadline/deadline_filter.cc\",\"file_line\":69,\"grpc_status\":4}\n",
            "W0000 00:00:1739878745.346358    2763 context.cc:647] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.\n",
            "E0000 00:00:1739878745.346544    2763 coordination_service_agent.cc:676] Shutdown() was called while coordination agent is in error state, implying that distributed execution failed. Note: agent will still shutdown anyway. Agent status: DEADLINE_EXCEEDED: Deadline Exceeded\n",
            "\n",
            "RPC: /tensorflow.CoordinationService/RegisterTask\n",
            "This is usually caused by an earlier error during execution. Check the logs of (a) this task, (b) the leader (usually slice 0 task 0) and (c) the scheduler (e.g. preemption, eviction) for an earlier error to debug further.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [tf.keras.callbacks.BackupAndRestore(backup_dir='/tmp/backup')]\n",
        "\n",
        "with strategy.scope():\n",
        "    multi_worker_model = mnist_setup.build_and_compile_cnn_model()\n",
        "\n",
        "multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU5hm926o6S8",
        "outputId": "3cb52c60-e799-481c-8686-6968944dfcfb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.1120 - loss: 2.2961\n",
            "Epoch 2/3\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - accuracy: 0.3346 - loss: 2.2340\n",
            "Epoch 3/3\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - accuracy: 0.5356 - loss: 2.1709\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a75a4ce33d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat job_0.log\n"
      ],
      "metadata": {
        "id": "DYzjyvIyo-4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/tmp/keras_model'\n",
        "\n",
        "def _is_chief(task_type, task_id):\n",
        "    return task_type == 'worker' and task_id == 0\n",
        "\n",
        "def write_filepath(filepath, task_type, task_id):\n",
        "    if not _is_chief(task_type, task_id):\n",
        "        temp_dir = f\"workertemp_{task_id}\"\n",
        "        tf.io.gfile.makedirs(temp_dir)\n",
        "        return os.path.join(temp_dir, os.path.basename(filepath))\n",
        "    return filepath\n",
        "\n",
        "task_type, task_id = strategy.cluster_resolver.task_type, strategy.cluster_resolver.task_id\n",
        "write_model_path = write_filepath(model_path, task_type, task_id)\n",
        "multi_worker_model.save(write_model_path)\n"
      ],
      "metadata": {
        "id": "L26X8J7P4cpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ.pop('TF_CONFIG', None)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nhCJYSqG4lAg",
        "outputId": "75e3f181-c998-4f7f-d95b-76decad4375e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"cluster\": {\"worker\": [\"localhost:12345\", \"localhost:23456\"]}, \"task\": {\"type\": \"worker\", \"index\": 1}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M61JDgBM4mUf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}